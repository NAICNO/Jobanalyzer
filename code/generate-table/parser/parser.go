// Code generated by goyacc -o parser.go parser.y. DO NOT EDIT.

//line parser.y:4
//go:generate goyacc -o parser.go parser.y

package parser

import __yyfmt__ "fmt"

//line parser.y:6

import (
	"bufio"
	"errors"
	"fmt"
	"io"
	"regexp"
	"strings"
)

// Generate-table syntax tree.  Names are never "" unless noted.

type TableBlock struct {
	TableName string
	Prefix    []string // completely unedited lines
	Fields    FieldSect
	Generate  string    // "" if no such section
	Summary   *HelpSect // nil if no such section
	Help      *HelpSect // nil if no such section
	Aliases   []Alias   // empty if no such section
	Defaults  []string  // empty if no such section
}

type FieldSect struct {
	Type   string
	Fields []Field // empty if no fields
}

type Field struct {
	Name  string
	Type  string
	Attrs []NV // quotes removed but escape codes intact in values
}

type HelpSect struct {
	Command string   // "" if no command name was present
	Text    []string // including leading and trailing blank lines
}

type Alias struct {
	Name   string
	Fields []string // never empty
}

type NV struct {
	Name  string
	Value string
}

// Parser interface

func NewParser(inputName string, input io.Reader) *Parser {
	return &Parser{
		inputName: inputName,
		input:     bufio.NewScanner(input),
	}
}

// Returns nil, nil at EOF

func (parser *Parser) Parse() (*TableBlock, error) {
	parser.inTable = false
	parser.doTokenize = false
	parser.errtxt = ""
	parser.qfront = nil
	parser.qtail = nil
	parser.table = nil
	r := yyParse(parser)
	if r != 0 {
		return nil, errors.New(parser.errtxt)
	}
	return parser.table, nil
}

//line parser.y:83
type yySymType struct {
	yys         int
	s           string
	ss          []string
	nv          NV
	nvs         []NV
	as          []Alias
	fieldSect   FieldSect
	fields      []Field
	field       Field
	helpSect    *HelpSect
	summarySect *HelpSect
}

const tIdent = 57346
const tText = 57347
const tString = 57348
const tTable = 57349
const tFields = 57350
const tGenerate = 57351
const tHelp = 57352
const tSummary = 57353
const tAliases = 57354
const tDefaults = 57355
const tElbat = 57356
const tStar = 57357
const tColon = 57358
const tComma = 57359
const tDot = 57360
const tEol = 57361
const tMark = 57362
const tLbrace = 57363
const tRbrace = 57364
const tBad = 57365

var yyToknames = [...]string{
	"$end",
	"error",
	"$unk",
	"tIdent",
	"tText",
	"tString",
	"tTable",
	"tFields",
	"tGenerate",
	"tHelp",
	"tSummary",
	"tAliases",
	"tDefaults",
	"tElbat",
	"tStar",
	"tColon",
	"tComma",
	"tDot",
	"tEol",
	"tMark",
	"tLbrace",
	"tRbrace",
	"tBad",
}

var yyStatenames = [...]string{}

const yyEofCode = 1
const yyErrCode = 2
const yyInitialStackSize = 16

//line parser.y:202

type token struct {
	tok  int
	text string
	next *token
}

type Parser struct /* implements yyLexer */ {
	input      *bufio.Scanner
	inputName  string
	lineno     int
	currline   int
	inTable    bool
	doTokenize bool
	errtxt     string
	qfront     *token
	qtail      *token
	table      *TableBlock
}

func (p *Parser) getLine() (string, bool) {
	p.currline = p.lineno
	if !p.input.Scan() {
		return "", false
	}
	s := p.input.Text()
	p.lineno++
	for {
		before, found := strings.CutSuffix(s, "\\")
		if !found {
			break
		}
		s = before
		if !p.input.Scan() {
			break
		}
		s += p.input.Text()
		p.lineno++
	}
	return s, true
}

func (p *Parser) enqueue(t int, s string) {
	n := &token{t, s, nil}
	if p.qfront == nil {
		p.qfront = n
	} else {
		p.qtail.next = n
	}
	p.qtail = n
}

func (p *Parser) dequeue() (int, string, bool) {
	if p.qfront == nil {
		return 0, "", false
	}
	n := p.qfront
	p.qfront = n.next
	if p.qfront == nil {
		p.qtail = nil
	}
	return n.tok, n.text, true
}

var (
	tablePrefix        = regexp.MustCompile(`^/\*TABLE(?:\s+(.*))?$`)
	blankOrCommentLine = regexp.MustCompile(`^\s*(?:#.*)?$`)
	sectionheader      = regexp.MustCompile(`^(ELBAT\*/|%%|FIELDS|GENERATE|SUMMARY|HELP|ALIASES|DEFAULTS)(?:\s+(.*))?$`)
)

var keyword = map[string]int{
	"ELBAT*/":  tElbat,
	"%%":       tMark,
	"FIELDS":   tFields,
	"GENERATE": tGenerate,
	"SUMMARY":  tSummary,
	"HELP":     tHelp,
	"ALIASES":  tAliases,
	"DEFAULTS": tDefaults,
}

func (p *Parser) Lex(lval *yySymType) (tok int) {
	if !p.inTable {
		for {
			s, haveLine := p.getLine()
			if !haveLine {
				return -1
			}
			if m := tablePrefix.FindStringSubmatch(s); m != nil {
				p.inTable = true
				p.qfront = nil
				p.qtail = nil
				p.tokenize(m[1])
				return tTable
			}
		}
	}
	if tok, text, ok := p.dequeue(); ok {
		lval.s = text
		return tok
	}
Scanner:
	for {
		s, haveLine := p.getLine()
		if !haveLine {
			p.inTable = false
			return -1
		}
		if m := sectionheader.FindStringSubmatch(s); m != nil {
			t := keyword[m[1]]
			switch t {
			case 0:
				t = tBad
			case tElbat:
				p.inTable = false
			case tMark:
				p.enqueue(tEol, "")
			default:
				p.tokenize(m[2])
			}
			return t
		}
		if !p.doTokenize {
			lval.s = s
			p.enqueue(tEol, "")
			return tText
		}
		if blankOrCommentLine.MatchString(s) {
			continue Scanner
		}
		p.tokenize(s)
		tok, text, _ := p.dequeue()
		lval.s = text
		return tok
	}
}

// tokenize() always pushes at least eol

func (p *Parser) tokenize(s string) {
	r := strings.NewReader(s)
Scanner:
	for {
		c, _, err := r.ReadRune()
		if err != nil {
			break Scanner
		}
		switch c {
		case ' ', '\t', '\n', '\r':
			continue Scanner
		case '.':
			p.enqueue(tDot, "")
		case ':':
			p.enqueue(tColon, "")
		case ',':
			p.enqueue(tComma, "")
		case '*':
			p.enqueue(tStar, "")
		case '[':
			p.enqueue(tLbrace, "")
		case ']':
			p.enqueue(tRbrace, "")
		case '"':
			s := ""
		String:
			for {
				c, _, err := r.ReadRune()
				if err != nil {
					p.enqueue(tBad, "End of input in string")
					break Scanner
				}
				if c == '"' {
					break String
				}
				if c == '\\' {
					c, _, err = r.ReadRune()
					if err != nil {
						p.enqueue(tBad, "End of input in string")
						break Scanner
					}
				}
				s = s + string(c)
			}
			p.enqueue(tString, s)
		default:
			if c >= 'a' && c <= 'z' || c >= 'A' && c <= 'Z' {
				s := string(c)
			Ident:
				for {
					c, _, err := r.ReadRune()
					if err != nil {
						break Ident
					}
					// "Not whitespace and not comma" would also be an acceptable guard here, but
					// this covers the chars traditionally used in idents.
					if c >= 'a' && c <= 'z' || c >= 'A' && c <= 'Z' || c >= '0' && c <= '9' ||
						c == '/' || c == '_' || c == '-' || c == '%' {
						s += string(c)
					} else {
						r.UnreadRune()
						break Ident
					}
				}
				p.enqueue(tIdent, s)
			} else {
				p.Error(fmt.Sprintf("Unknown character %c", c))
				p.enqueue(tBad, "")
				break Scanner
			}
		}
	}
	p.enqueue(tEol, "")
}

func (p *Parser) Error(s string) {
	if p.errtxt == "" {
		p.errtxt = fmt.Sprintf("%s:%d: %s", p.inputName, p.currline, s)
	}
}

//line yacctab:1
var yyExca = [...]int8{
	-1, 1,
	1, -1,
	-2, 0,
}

const yyPrivate = 57344

const yyLast = 74

var yyAct = [...]int8{
	57, 6, 22, 25, 26, 33, 63, 67, 71, 63,
	8, 62, 54, 53, 48, 23, 39, 31, 18, 51,
	14, 24, 65, 4, 34, 70, 32, 44, 36, 20,
	28, 16, 12, 2, 72, 10, 41, 58, 42, 68,
	64, 50, 47, 26, 38, 30, 3, 52, 45, 29,
	55, 37, 21, 56, 17, 13, 60, 7, 19, 27,
	49, 40, 11, 66, 59, 69, 35, 61, 43, 5,
	15, 46, 9, 1,
}

var yyPact = [...]int16{
	26, -1000, 42, 4, -1000, -10, 30, 24, -1000, -1000,
	1, 22, -1000, -1, -1000, 18, -1000, 0, -1000, 20,
	-1000, 41, -2, 0, -17, -1000, 6, 16, -1000, 40,
	-3, -1000, -1000, 0, 39, 14, -1000, 38, -5, -1000,
	37, -1000, -1000, 5, -1000, -6, -7, -1000, -1000, -1000,
	0, -1000, 33, -1000, -1000, 30, -1000, -8, -1000, 36,
	30, 3, -1000, 35, 33, -1000, -1000, 9, -1000, -11,
	28, -1000, -1000,
}

var yyPgo = [...]int8{
	0, 73, 2, 72, 71, 3, 70, 1, 69, 0,
	68, 67, 66, 64, 63, 62, 61, 60, 59, 58,
	57, 55, 54, 52, 51, 49, 48, 47,
}

var yyR1 = [...]int8{
	0, 1, 1, 8, 21, 20, 22, 15, 16, 16,
	17, 11, 11, 14, 6, 23, 6, 18, 24, 18,
	19, 25, 19, 12, 26, 12, 13, 13, 10, 27,
	10, 2, 2, 2, 7, 7, 3, 4, 4, 9,
	9, 5, 5,
}

var yyR2 = [...]int8{
	0, 0, 12, 1, 0, 3, 0, 5, 0, 2,
	4, 0, 2, 3, 0, 0, 4, 0, 0, 5,
	0, 0, 5, 0, 0, 4, 0, 4, 0, 0,
	4, 2, 3, 1, 0, 2, 2, 0, 1, 1,
	3, 1, 3,
}

var yyChk = [...]int16{
	-1000, -1, 7, 4, 19, -8, -7, -20, 20, -3,
	5, -15, 8, -21, 19, -6, 9, -22, 19, -19,
	11, -23, -2, 15, 21, -5, 4, -18, 10, -25,
	4, 19, -2, 22, 18, -12, 12, -24, 4, 19,
	-16, -2, -5, -10, 13, -26, -4, 4, 19, -17,
	4, 14, -27, 19, 19, -7, -2, -9, 4, -13,
	-7, -11, 19, 17, 4, 19, -14, 4, 4, -9,
	16, 19, 6,
}

var yyDef = [...]int8{
	1, -2, 0, 0, 34, 0, 3, 0, 4, 35,
	0, 14, 6, 0, 36, 20, 15, 0, 5, 17,
	21, 0, 0, 0, 0, 33, 41, 23, 18, 0,
	0, 8, 31, 0, 0, 28, 24, 37, 0, 16,
	7, 32, 42, 0, 29, 0, 0, 38, 34, 9,
	0, 2, 0, 26, 34, 22, 11, 0, 39, 25,
	19, 0, 30, 0, 0, 10, 12, 0, 40, 0,
	0, 27, 13,
}

var yyTok1 = [...]int8{
	1,
}

var yyTok2 = [...]int8{
	2, 3, 4, 5, 6, 7, 8, 9, 10, 11,
	12, 13, 14, 15, 16, 17, 18, 19, 20, 21,
	22, 23,
}

var yyTok3 = [...]int8{
	0,
}

var yyErrorMessages = [...]struct {
	state int
	token int
	msg   string
}{}

//line yaccpar:1

/*	parser for yacc output	*/

var (
	yyDebug        = 0
	yyErrorVerbose = false
)

type yyLexer interface {
	Lex(lval *yySymType) int
	Error(s string)
}

type yyParser interface {
	Parse(yyLexer) int
	Lookahead() int
}

type yyParserImpl struct {
	lval  yySymType
	stack [yyInitialStackSize]yySymType
	char  int
}

func (p *yyParserImpl) Lookahead() int {
	return p.char
}

func yyNewParser() yyParser {
	return &yyParserImpl{}
}

const yyFlag = -1000

func yyTokname(c int) string {
	if c >= 1 && c-1 < len(yyToknames) {
		if yyToknames[c-1] != "" {
			return yyToknames[c-1]
		}
	}
	return __yyfmt__.Sprintf("tok-%v", c)
}

func yyStatname(s int) string {
	if s >= 0 && s < len(yyStatenames) {
		if yyStatenames[s] != "" {
			return yyStatenames[s]
		}
	}
	return __yyfmt__.Sprintf("state-%v", s)
}

func yyErrorMessage(state, lookAhead int) string {
	const TOKSTART = 4

	if !yyErrorVerbose {
		return "syntax error"
	}

	for _, e := range yyErrorMessages {
		if e.state == state && e.token == lookAhead {
			return "syntax error: " + e.msg
		}
	}

	res := "syntax error: unexpected " + yyTokname(lookAhead)

	// To match Bison, suggest at most four expected tokens.
	expected := make([]int, 0, 4)

	// Look for shiftable tokens.
	base := int(yyPact[state])
	for tok := TOKSTART; tok-1 < len(yyToknames); tok++ {
		if n := base + tok; n >= 0 && n < yyLast && int(yyChk[int(yyAct[n])]) == tok {
			if len(expected) == cap(expected) {
				return res
			}
			expected = append(expected, tok)
		}
	}

	if yyDef[state] == -2 {
		i := 0
		for yyExca[i] != -1 || int(yyExca[i+1]) != state {
			i += 2
		}

		// Look for tokens that we accept or reduce.
		for i += 2; yyExca[i] >= 0; i += 2 {
			tok := int(yyExca[i])
			if tok < TOKSTART || yyExca[i+1] == 0 {
				continue
			}
			if len(expected) == cap(expected) {
				return res
			}
			expected = append(expected, tok)
		}

		// If the default action is to accept or reduce, give up.
		if yyExca[i+1] != 0 {
			return res
		}
	}

	for i, tok := range expected {
		if i == 0 {
			res += ", expecting "
		} else {
			res += " or "
		}
		res += yyTokname(tok)
	}
	return res
}

func yylex1(lex yyLexer, lval *yySymType) (char, token int) {
	token = 0
	char = lex.Lex(lval)
	if char <= 0 {
		token = int(yyTok1[0])
		goto out
	}
	if char < len(yyTok1) {
		token = int(yyTok1[char])
		goto out
	}
	if char >= yyPrivate {
		if char < yyPrivate+len(yyTok2) {
			token = int(yyTok2[char-yyPrivate])
			goto out
		}
	}
	for i := 0; i < len(yyTok3); i += 2 {
		token = int(yyTok3[i+0])
		if token == char {
			token = int(yyTok3[i+1])
			goto out
		}
	}

out:
	if token == 0 {
		token = int(yyTok2[1]) /* unknown char */
	}
	if yyDebug >= 3 {
		__yyfmt__.Printf("lex %s(%d)\n", yyTokname(token), uint(char))
	}
	return char, token
}

func yyParse(yylex yyLexer) int {
	return yyNewParser().Parse(yylex)
}

func (yyrcvr *yyParserImpl) Parse(yylex yyLexer) int {
	var yyn int
	var yyVAL yySymType
	var yyDollar []yySymType
	_ = yyDollar // silence set and not used
	yyS := yyrcvr.stack[:]

	Nerrs := 0   /* number of errors */
	Errflag := 0 /* error recovery flag */
	yystate := 0
	yyrcvr.char = -1
	yytoken := -1 // yyrcvr.char translated into internal numbering
	defer func() {
		// Make sure we report no lookahead when not parsing.
		yystate = -1
		yyrcvr.char = -1
		yytoken = -1
	}()
	yyp := -1
	goto yystack

ret0:
	return 0

ret1:
	return 1

yystack:
	/* put a state and value onto the stack */
	if yyDebug >= 4 {
		__yyfmt__.Printf("char %v in %v\n", yyTokname(yytoken), yyStatname(yystate))
	}

	yyp++
	if yyp >= len(yyS) {
		nyys := make([]yySymType, len(yyS)*2)
		copy(nyys, yyS)
		yyS = nyys
	}
	yyS[yyp] = yyVAL
	yyS[yyp].yys = yystate

yynewstate:
	yyn = int(yyPact[yystate])
	if yyn <= yyFlag {
		goto yydefault /* simple state */
	}
	if yyrcvr.char < 0 {
		yyrcvr.char, yytoken = yylex1(yylex, &yyrcvr.lval)
	}
	yyn += yytoken
	if yyn < 0 || yyn >= yyLast {
		goto yydefault
	}
	yyn = int(yyAct[yyn])
	if int(yyChk[yyn]) == yytoken { /* valid shift */
		yyrcvr.char = -1
		yytoken = -1
		yyVAL = yyrcvr.lval
		yystate = yyn
		if Errflag > 0 {
			Errflag--
		}
		goto yystack
	}

yydefault:
	/* default state action */
	yyn = int(yyDef[yystate])
	if yyn == -2 {
		if yyrcvr.char < 0 {
			yyrcvr.char, yytoken = yylex1(yylex, &yyrcvr.lval)
		}

		/* look through exception table */
		xi := 0
		for {
			if yyExca[xi+0] == -1 && int(yyExca[xi+1]) == yystate {
				break
			}
			xi += 2
		}
		for xi += 2; ; xi += 2 {
			yyn = int(yyExca[xi+0])
			if yyn < 0 || yyn == yytoken {
				break
			}
		}
		yyn = int(yyExca[xi+1])
		if yyn < 0 {
			goto ret0
		}
	}
	if yyn == 0 {
		/* error ... attempt to resume parsing */
		switch Errflag {
		case 0: /* brand new error */
			yylex.Error(yyErrorMessage(yystate, yytoken))
			Nerrs++
			if yyDebug >= 1 {
				__yyfmt__.Printf("%s", yyStatname(yystate))
				__yyfmt__.Printf(" saw %s\n", yyTokname(yytoken))
			}
			fallthrough

		case 1, 2: /* incompletely recovered error ... try again */
			Errflag = 3

			/* find a state where "error" is a legal shift action */
			for yyp >= 0 {
				yyn = int(yyPact[yyS[yyp].yys]) + yyErrCode
				if yyn >= 0 && yyn < yyLast {
					yystate = int(yyAct[yyn]) /* simulate a shift of "error" */
					if int(yyChk[yystate]) == yyErrCode {
						goto yystack
					}
				}

				/* the current p has no shift on "error", pop stack */
				if yyDebug >= 2 {
					__yyfmt__.Printf("error recovery pops state %d\n", yyS[yyp].yys)
				}
				yyp--
			}
			/* there is no state on the stack with an error shift ... abort */
			goto ret1

		case 3: /* no shift yet; clobber input char */
			if yyDebug >= 2 {
				__yyfmt__.Printf("error recovery discards %s\n", yyTokname(yytoken))
			}
			if yytoken == yyEofCode {
				goto ret1
			}
			yyrcvr.char = -1
			yytoken = -1
			goto yynewstate /* try again in the same state */
		}
	}

	/* reduction by production yyn */
	if yyDebug >= 2 {
		__yyfmt__.Printf("reduce %v in:\n\t%v\n", yyn, yyStatname(yystate))
	}

	yynt := yyn
	yypt := yyp
	_ = yypt // guard against "declared and not used"

	yyp -= int(yyR2[yyn])
	// yyp is now the index of $0. Perform the default action. Iff the
	// reduced production is Îµ, $1 is possibly out of range.
	if yyp+1 >= len(yyS) {
		nyys := make([]yySymType, len(yyS)*2)
		copy(nyys, yyS)
		yyS = nyys
	}
	yyVAL = yyS[yyp+1]

	/* consult goto table to find next state */
	yyn = int(yyR1[yyn])
	yyg := int(yyPgo[yyn])
	yyj := yyg + yyS[yyp].yys + 1

	if yyj >= yyLast {
		yystate = int(yyAct[yyg])
	} else {
		yystate = int(yyAct[yyj])
		if int(yyChk[yystate]) != -yyn {
			yystate = int(yyAct[yyg])
		}
	}
	// dummy call; replaced with literal code
	switch yynt {

	case 1:
		yyDollar = yyS[yypt-0 : yypt+1]
//line parser.y:115
		{
			yylex.(*Parser).table = nil
		}
	case 2:
		yyDollar = yyS[yypt-12 : yypt+1]
//line parser.y:126
		{
			yylex.(*Parser).table = &TableBlock{
				TableName: yyDollar[2].s,
				Prefix:    yyDollar[4].ss,
				Fields:    yyDollar[6].fieldSect,
				Generate:  yyDollar[7].s,
				Summary:   yyDollar[8].helpSect,
				Help:      yyDollar[9].helpSect,
				Aliases:   yyDollar[10].as,
				Defaults:  yyDollar[11].ss,
			}
		}
	case 4:
		yyDollar = yyS[yypt-1 : yypt+1]
//line parser.y:142
		{
			yylex.(*Parser).doTokenize = true
		}
	case 6:
		yyDollar = yyS[yypt-1 : yypt+1]
//line parser.y:144
		{
			yylex.(*Parser).doTokenize = true
		}
	case 7:
		yyDollar = yyS[yypt-5 : yypt+1]
//line parser.y:145
		{
			yyVAL.fieldSect = FieldSect{yyDollar[3].s, yyDollar[5].fields}
		}
	case 8:
		yyDollar = yyS[yypt-0 : yypt+1]
//line parser.y:147
		{
			yyVAL.fields = make([]Field, 0)
		}
	case 9:
		yyDollar = yyS[yypt-2 : yypt+1]
//line parser.y:148
		{
			yyVAL.fields = append(yyDollar[1].fields, yyDollar[2].field)
		}
	case 10:
		yyDollar = yyS[yypt-4 : yypt+1]
//line parser.y:150
		{
			yyVAL.field = Field{yyDollar[1].s, yyDollar[2].s, yyDollar[3].nvs}
		}
	case 11:
		yyDollar = yyS[yypt-0 : yypt+1]
//line parser.y:151
		{
			yyVAL.nvs = make([]NV, 0)
		}
	case 12:
		yyDollar = yyS[yypt-2 : yypt+1]
//line parser.y:152
		{
			yyVAL.nvs = append(yyDollar[1].nvs, yyDollar[2].nv)
		}
	case 13:
		yyDollar = yyS[yypt-3 : yypt+1]
//line parser.y:154
		{
			yyVAL.nv = NV{yyDollar[1].s, yyDollar[3].s}
		}
	case 14:
		yyDollar = yyS[yypt-0 : yypt+1]
//line parser.y:156
		{
			yyVAL.s = ""
		}
	case 15:
		yyDollar = yyS[yypt-1 : yypt+1]
//line parser.y:157
		{
			yylex.(*Parser).doTokenize = true
		}
	case 16:
		yyDollar = yyS[yypt-4 : yypt+1]
//line parser.y:157
		{
			yyVAL.s = yyDollar[3].s
		}
	case 17:
		yyDollar = yyS[yypt-0 : yypt+1]
//line parser.y:160
		{
			yyVAL.helpSect = nil
		}
	case 18:
		yyDollar = yyS[yypt-1 : yypt+1]
//line parser.y:161
		{
			yylex.(*Parser).doTokenize = false
		}
	case 19:
		yyDollar = yyS[yypt-5 : yypt+1]
//line parser.y:162
		{
			yyVAL.helpSect = &HelpSect{yyDollar[3].s, yyDollar[5].ss}
		}
	case 20:
		yyDollar = yyS[yypt-0 : yypt+1]
//line parser.y:165
		{
			yyVAL.helpSect = nil
		}
	case 21:
		yyDollar = yyS[yypt-1 : yypt+1]
//line parser.y:166
		{
			yylex.(*Parser).doTokenize = false
		}
	case 22:
		yyDollar = yyS[yypt-5 : yypt+1]
//line parser.y:167
		{
			yyVAL.helpSect = &HelpSect{yyDollar[3].s, yyDollar[5].ss}
		}
	case 23:
		yyDollar = yyS[yypt-0 : yypt+1]
//line parser.y:170
		{
			yyVAL.as = make([]Alias, 0)
		}
	case 24:
		yyDollar = yyS[yypt-1 : yypt+1]
//line parser.y:171
		{
			yylex.(*Parser).doTokenize = true
		}
	case 25:
		yyDollar = yyS[yypt-4 : yypt+1]
//line parser.y:172
		{
			yyVAL.as = yyDollar[4].as
		}
	case 26:
		yyDollar = yyS[yypt-0 : yypt+1]
//line parser.y:174
		{
			yyVAL.as = make([]Alias, 0)
		}
	case 27:
		yyDollar = yyS[yypt-4 : yypt+1]
//line parser.y:175
		{
			yyVAL.as = append(yyDollar[1].as, Alias{yyDollar[2].s, yyDollar[3].ss})
		}
	case 28:
		yyDollar = yyS[yypt-0 : yypt+1]
//line parser.y:178
		{
			yyVAL.ss = nil
		}
	case 29:
		yyDollar = yyS[yypt-1 : yypt+1]
//line parser.y:179
		{
			yylex.(*Parser).doTokenize = true
		}
	case 30:
		yyDollar = yyS[yypt-4 : yypt+1]
//line parser.y:179
		{
			yyVAL.ss = yyDollar[3].ss
		}
	case 31:
		yyDollar = yyS[yypt-2 : yypt+1]
//line parser.y:182
		{
			yyVAL.s = "*" + yyDollar[2].s
		}
	case 32:
		yyDollar = yyS[yypt-3 : yypt+1]
//line parser.y:183
		{
			yyVAL.s = "[]" + yyDollar[3].s
		}
	case 34:
		yyDollar = yyS[yypt-0 : yypt+1]
//line parser.y:187
		{
			yyVAL.ss = make([]string, 0)
		}
	case 35:
		yyDollar = yyS[yypt-2 : yypt+1]
//line parser.y:188
		{
			yyVAL.ss = append(yyDollar[1].ss, yyDollar[2].s)
		}
	case 37:
		yyDollar = yyS[yypt-0 : yypt+1]
//line parser.y:192
		{
			yyVAL.s = ""
		}
	case 39:
		yyDollar = yyS[yypt-1 : yypt+1]
//line parser.y:195
		{
			yyVAL.ss = []string{yyDollar[1].s}
		}
	case 40:
		yyDollar = yyS[yypt-3 : yypt+1]
//line parser.y:196
		{
			yyVAL.ss = append(yyDollar[1].ss, yyDollar[3].s)
		}
	case 42:
		yyDollar = yyS[yypt-3 : yypt+1]
//line parser.y:199
		{
			yyVAL.s = yyDollar[1].s + "." + yyDollar[3].s
		}
	}
	goto yystack /* stack new state and value */
}
